{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Trong file này dùng để sử lí dữ liệu, \n",
    "Input: file dữ liệu của thầy data_email.txt\n",
    "Output: chia làm 4 file \n",
    "    +train-feature.txt\n",
    "    +train-label.txt\n",
    "    +test_feature.txt\n",
    "    +test_label.txt\n",
    "Số lượng mẫu trong train là 80% file ban đầu, test là 20%\n",
    "Trong file feature có 3 cột:\n",
    "       + Cột 1 là số thứ tự của email\n",
    "        + Cột 2 là vị trí của từ trong từ điển\n",
    "        + Cột 3 là số lần suất hiện của từ trong email thứ i\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyvi import ViTokenizer #For split vietnamese words\n",
    "#import pandas as pd #For reading xlsx file\n",
    "from gensim.parsing.preprocessing import strip_non_alphanum, strip_multiple_whitespaces,preprocess_string, split_alphanum, strip_short, strip_numeric\n",
    "import re #For preprocessing raw text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6771\n"
     ]
    }
   ],
   "source": [
    "f = open('data_email.txt','r')\n",
    "y = []\n",
    "data=[]\n",
    "dictionary = {''}\n",
    "sumN = 407\n",
    "N_train=int(sumN*0.8)\n",
    "N_test=sumN-N_train\n",
    "for i,s in enumerate(f):\n",
    "    s = re.sub(r\"http\\S+\", \"\", s)\n",
    "    s= strip_non_alphanum(s).lower().strip()\n",
    "    s = split_alphanum(s)\n",
    "    s = ViTokenizer.tokenize(s)\n",
    "    if s[0]=='n':\n",
    "        y.append('0')\n",
    "        s= s[8:]\n",
    "        tokens = s.split(\" \")\n",
    "        for t in tokens:\n",
    "            dictionary.add(t)\n",
    "    elif s[0]=='s':\n",
    "        y.append('1')\n",
    "        s=s[5:]\n",
    "        tokens = s.split(\" \")\n",
    "        for t in tokens:\n",
    "            dictionary.add(t)\n",
    "    data.append(s)\n",
    "fw1=open('train-features.txt','+w')\n",
    "\n",
    "train_str=[];\n",
    "for i,d in enumerate(data):\n",
    "    # Nếu mà số lượng email nhỏ hơn N_train thì tiếp tục ghi vào file train\n",
    "    if i<N_train:\n",
    "        token = d.split(\" \")\n",
    "        setTok={}\n",
    "        for t in token:\n",
    "            if t in setTok.keys():\n",
    "                setTok[t]=setTok[t]+1\n",
    "            else:\n",
    "                setTok[t]=1;\n",
    "        for h,k in setTok.items():\n",
    "            for index,di in enumerate(dictionary):\n",
    "                if(h==di):\n",
    "                    # từng dòng trong file feature\n",
    "                    m=('%d'%i)+' '+('%d'%index)+' '+('%d'%k);\n",
    "                    fw1.write('%s\\n'%(m))\n",
    "    # Nếu đủ số lượng cho train thì mở file test để lưu tiếp dữ liệ\n",
    "    elif(N_train==i):\n",
    "        fw1.close()\n",
    "        fw2=open('test-features.txt','+w')\n",
    "    else:\n",
    "        token = d.split(\" \")\n",
    "        setTok={}\n",
    "        for t in token:\n",
    "            if t in setTok.keys():\n",
    "                setTok[t]=setTok[t]+1\n",
    "            else:\n",
    "                setTok[t]=1;\n",
    "        for h,k in setTok.items():\n",
    "            for index,di in enumerate(dictionary):\n",
    "                if(h==di):\n",
    "                    m=('%d'%(i-N_train-1))+' '+('%d'%index)+' '+('%d'%k); \n",
    "                    fw2.write('%s\\n'%(m))\n",
    "fw2.close()\n",
    "fw3=open('train-labels.txt','+w')\n",
    "for i,label in enumerate(y):\n",
    "    if(i<N_train):\n",
    "        fw3.write('%s\\n'%(label))\n",
    "    elif(i==N_train):\n",
    "        fw3.close()\n",
    "        fw4=open('test-labels.txt','+w')\n",
    "    else:\n",
    "        fw4.write('%s\\n'%(label))\n",
    "fw4.close()\n",
    "#for i, word in enumerate(dictionary):\n",
    "#print(i)\n",
    "print(len(dictionary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1, 2, 3}\n"
     ]
    }
   ],
   "source": [
    "    A={1,2}\n",
    "    A.add(1)\n",
    "    A.add(3)\n",
    "    print(A)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
