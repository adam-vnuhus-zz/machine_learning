{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from sklearn.utils import shuffle\n",
    "from pyvi import ViTokenizer #For split vietnamese words\n",
    "from gensim.parsing.preprocessing import strip_non_alphanum, strip_multiple_whitespaces,preprocess_string, split_alphanum, strip_short, strip_numeric\n",
    "import re\n",
    "import numpy as np\n",
    "from scipy.sparse import coo_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def raw_text_preprocess(raw):\n",
    "    raw = raw.lower()\n",
    "    raw = re.sub(r\"(http\\S+)|(https\\S+)\", \"URL_Change\", raw)\n",
    "    raw = re.sub(r\"(www\\S+)|(\\S+@\\S+)\", \"URL_Change\", raw)\n",
    "    raw = re.sub(r\"([0-9][0-9]/[0-9][0-9]/[0-9][0-9][0-9][0-9])|([0-9][0-9]/[0-9][0-9])|([0-9][0-9]/[0-9][0-9][0-9][0-9])\", \"DATE_Change\", raw)\n",
    "    raw = re.sub(r\"([0-9][0-9]-[0-9][0-9]-[0-9][0-9][0-9][0-9])|([0-9][0-9]-[0-9][0-9])|([0-9][0-9]-[0-9][0-9][0-9][0-9])\", \"DATE_Change\", raw)\n",
    "    raw = strip_numeric(raw)\n",
    "    raw = strip_short(raw, minsize=2)\n",
    "    raw = ViTokenizer.tokenize(raw)\n",
    "    return raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Đọc mail. chuyển về list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = []\n",
    "label = []\n",
    "with open('data_email.txt','r', encoding= 'utf-8') as f:\n",
    "    for line in f:\n",
    "        doc.append(line[:])\n",
    "#doc = shuffle(doc,random_state = 0)\n",
    "document = []\n",
    "for d in doc:\n",
    "    ind = d.find('|')        \n",
    "    if ind == 5:   \n",
    "        label.append(1)\n",
    "    elif ind == 8:\n",
    "        label.append(0)\n",
    "    document.append(d[ind+2:])\n",
    "document = [raw_text_preprocess(d) for d in document]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chia 5 fold để test và train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_fold(i):\n",
    "    document_test = document[(i-1)*80:i*80]\n",
    "    label_test = label[(i-1)*80:i*80]\n",
    "    document_train = document[:(i-1)*80+1]+document[i*80+1:]\n",
    "    label_train = label[:(i-1)*80+1]+label[i*80+1:]\n",
    "    return (document_test,label_test,document_train ,label_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tạo thư viện các từ có trong dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_word(document):\n",
    "    bow = document[0].split(\" \")\n",
    "    set_dict=set(bow)\n",
    "    for doc in document:\n",
    "        bow = doc.split(\" \")\n",
    "        set_dict = set_dict.union(set(bow))\n",
    "  \n",
    "    #set_dict = sorted(set_dict.keys())\n",
    "    #print(set_dict)\n",
    "    #print(len(set_dict))\n",
    "    return (set_dict)\n",
    "#\n",
    "set_dict = dict_word(document)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Biến mỗi mail thành một dict(word, number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(document, set_dict):\n",
    "    word_dict = []\n",
    "    for doc in document:\n",
    "        bow = doc.split(\" \")\n",
    "        wordDict = dict.fromkeys(set_dict, 0)\n",
    "        for word in bow:\n",
    "            if len(set({word}) & set_dict) ==1 :\n",
    "                 wordDict[word]+=1\n",
    "        word_dict.append(wordDict)\n",
    "    return (word_dict)\n",
    "#\n",
    "word_dict = read_data(document, set_dict)\n",
    "#print(word_dict[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tính TF: biến mỗi mail thành một dict(word, frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_TF(word_dict, bow):\n",
    "    tf_dict = {}\n",
    "    bow_count = len(bow)\n",
    "    for word, count in word_dict.items():\n",
    "        tf_dict[word] = count/float(bow_count)\n",
    "    \n",
    "    return tf_dict    \n",
    "#\n",
    "bow = document[0].split(\" \")\n",
    "tf_bowA = compute_TF(word_dict[0], bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tính IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_IDF(doc_list):\n",
    "    import math\n",
    "    idf_dict = {}\n",
    "    N = len(doc_list)\n",
    "    \n",
    "    #count number of documents that contain this word\n",
    "    idf_dict = dict.fromkeys(doc_list[0].keys(), 0)\n",
    "    for doc in doc_list:\n",
    "        for word, count in doc.items():\n",
    "            if count > 0:\n",
    "                idf_dict[word] += 1\n",
    "                \n",
    "    for word, count in idf_dict.items():\n",
    "        idf_dict[word] = math.log(N/float(count))\n",
    "        \n",
    "    return idf_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
