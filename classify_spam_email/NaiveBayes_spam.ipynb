{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### link: https://viblo.asia/p/ly-thuyet-ve-mang-bayes-va-ung-dung-vao-bai-toan-loc-thu-rac-07LKXzkelV4\n",
    "\n",
    "\n",
    "### https://www.kaggle.com/pablovargas/naive-bayes-svm-spam-filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyvi import ViTokenizer #For split vietnamese words\n",
    "import pandas as pd #For reading xlsx file\n",
    "from gensim.parsing.preprocessing import strip_non_alphanum, strip_multiple_whitespaces,preprocess_string, split_alphanum, strip_short, strip_numeric\n",
    "import re "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('spam.txt', 'r', encoding = 'utf-8') as f:\n",
    "    \n",
    "    for line in f:\n",
    "#         line = re.sub(r\"\", \"\", line)\n",
    "        line = strip_non_alphanum(line).lower().strip()\n",
    "        ## Tách từ vô nghĩa\n",
    "        line = split_alphanum(line)\n",
    "        \n",
    "        ## Loại bỏ các từ đứng 1 mình\n",
    "        line = strip_short(line, minsize=2)\n",
    "        \n",
    "        ## Loại bỏ hết các số trong văn bản\n",
    "        line = strip_numeric(line)\n",
    "        \n",
    "        ## Ghép từ tiếng việt\n",
    "        line = ViTokenizer.tokenize(line)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def raw_text_preprocess(raw):\n",
    "#     raw = re.sub(r\"http\\S+\", \"\", raw)\n",
    "    raw = strip_non_alphanum(raw).lower().strip()\n",
    "#     raw = split_alphanum(raw)\n",
    "    raw = strip_short(raw, minsize=2)\n",
    "    raw = strip_numeric(raw)\n",
    "    raw = ViTokenizer.tokenize(raw)\n",
    "\n",
    "    return raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Đọc  dữ liệu đã thu nhập rồi xử lý"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62\n"
     ]
    }
   ],
   "source": [
    "document = []\n",
    "label = []\n",
    "with open('spam.txt', 'r', encoding = 'utf-8') as f:\n",
    "    for line in f:\n",
    "        document.append(line[6: ])\n",
    "        label.append(1)\n",
    "with open('nonspam_email.txt', 'r', encoding = 'utf-8') as f:\n",
    "    for line in f:\n",
    "        document.append(line[9: ])\n",
    "        label.append(0)\n",
    "print(len(document))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "document = [raw_text_preprocess(d) for d in document]\n",
    "document_test = document[10: 30]\n",
    "label_test = label[10: 30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xây dựng Bag_of_words\n",
    "    - Chứa tất cả các từ có trong tập dữ liệu\n",
    "    - Tách các văn bản thành các từ sau đó loại bỏ tất cả các những từ trùng nhau."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9945\n"
     ]
    }
   ],
   "source": [
    "set_words = []\n",
    "\n",
    "for doc in document:\n",
    "    words = doc.split(' ')\n",
    "    set_words += words\n",
    "    set(set_words)\n",
    "print(len(set_words))\n",
    "# print(set_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chuyển văn bản sang các vector\n",
    "    - Với mỗi văn bản trong tập dữ liệu, tạo thành 1 vecto 0 với số thuộc tính là chiều dài cảu bag of words.\n",
    "    - Sau đó kiêm tra xem từng từ trong bag of words có nằm trong văn bản không, nếu có thì gán thuộc tính đó bằng 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62, 9945)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "vectors = []\n",
    "\n",
    "for doc in document:\n",
    "    vector = np.zeros(len(set_words))\n",
    "    for i, word in enumerate(set_words):\n",
    "        if word in doc:\n",
    "            vector[i] = 1\n",
    "    vectors.append(vector)\n",
    "np.shape(vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tính các xác suất cần thiết của Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smoothing(a, b):\n",
    "    return float((a + 1)/(b + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39 23\n"
     ]
    }
   ],
   "source": [
    "spam = 0\n",
    "non_spam = 0\n",
    "\n",
    "for l in label:\n",
    "    if l == 1:\n",
    "        spam += 1\n",
    "    else:\n",
    "        non_spam += 1\n",
    "print(spam, non_spam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_coef = smoothing(spam, (spam + non_spam))\n",
    "non_spam_coef = smoothing(non_spam, (spam + non_spam))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Các xác suất thành phần"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bayes_matrix = np.zeros((len(set_words), 4))\n",
    "##app/spam, app/nonspam, nonapp/spam, nonapp/nonspam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, word in enumerate(set_words):\n",
    "    app_spam = 0\n",
    "    app_nonspam = 0\n",
    "    nonapp_spam = 0\n",
    "    nonapp_nonspam = 0\n",
    "    for k, v in enumerate(vectors):\n",
    "        if v[i] == 1:\n",
    "            if label[k] == 1:\n",
    "                app_spam += 1\n",
    "            else:\n",
    "                app_nonspam += 1\n",
    "        else:\n",
    "            if label[k] == 1:\n",
    "                nonapp_spam += 1\n",
    "            else:\n",
    "                nonapp_nonspam += 1\n",
    "                \n",
    "    bayes_matrix[i][0] = smoothing(app_spam, spam)\n",
    "    bayes_matrix[i][1] = smoothing(app_nonspam, non_spam)\n",
    "    bayes_matrix[i][2] = smoothing(nonapp_spam, spam)\n",
    "    bayes_matrix[i][3] = smoothing(nonapp_nonspam, non_spam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phân loại thư mới"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_document = document[30] \n",
    "new_document = raw_text_preprocess(new_document)\n",
    "\n",
    "#Vectorizer\n",
    "vector = np.zeros(len(set_words))\n",
    "for i, word in enumerate(set_words):\n",
    "    if word in new_document:\n",
    "        vector[i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = np.zeros(2)\n",
    "\n",
    "predict_spam = spam_coef #P(spam)\n",
    "predict_non_spam = non_spam_coef #P(non_spam)\n",
    "\n",
    "index = 0\n",
    "\n",
    "for i, v in enumerate(vector):\n",
    "    if v == 0:\n",
    "        predict_spam *= bayes_matrix[i][2] #P(xi|cj)\n",
    "        predict_non_spam *= bayes_matrix[i][3]\n",
    "    else:\n",
    "        predict_spam *= bayes_matrix[i][0]\n",
    "        predict_non_spam *= bayes_matrix[i][1]\n",
    "    \n",
    "    if predict_spam < 1e-10:\n",
    "        predict_spam *= 1000\n",
    "        log[0] += 1\n",
    "    \n",
    "    if predict_non_spam < 1e-10:\n",
    "        predict_non_spam *= 1000\n",
    "        log[1] +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(predict_spam, predict_non_spam, log):\n",
    "    while (log[0] > log[1]):\n",
    "        predict_spam /= 10\n",
    "        log[0] -=1\n",
    "        if predict_spam > predict_non_spam:\n",
    "            return True\n",
    "        \n",
    "    while(log[1] > log[0]):\n",
    "        predict_non_spam /= 10\n",
    "        log[1] -= 1\n",
    "        if predict_non_spam > predict_spam:\n",
    "            return False\n",
    "        \n",
    "    if predict_spam > predict_non_spam:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(mail):\n",
    "    mail = raw_text_preprocess(mail)\n",
    "    \n",
    "    vector = np.zeros(len(set_words))\n",
    "    for i, word in enumerate(set_words):\n",
    "        if word in mail:\n",
    "            vector[i] = 1\n",
    "    log = np.zeros(2)\n",
    "\n",
    "    predict_spam = spam_coef\n",
    "    predict_non_spam = non_spam_coef\n",
    "\n",
    "    for i, v in enumerate(vector):\n",
    "        if v == 0:\n",
    "            predict_spam *= bayes_matrix[i][2]\n",
    "            predict_non_spam *= bayes_matrix[i][3]\n",
    "        else:\n",
    "            predict_spam *= bayes_matrix[i][0]\n",
    "            predict_non_spam *= bayes_matrix[i][1]\n",
    "\n",
    "        if predict_spam < 1e-10:\n",
    "            predict_spam *= 1000\n",
    "            log[0] += 1\n",
    "\n",
    "        if predict_non_spam < 1e-10:\n",
    "            predict_non_spam *= 1000\n",
    "            log[1] +=1\n",
    "            \n",
    "    if compare(predict_spam, predict_non_spam, log):\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "pred = [predict(d) for d in document_test]\n",
    "accuracy_score(label_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
