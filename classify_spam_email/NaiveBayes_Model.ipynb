{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(X_train, y_train):\n",
    "    N,D = X_train.shape\n",
    "    classes, noElementOfClass = np.unique(y_train, return_counts=True)\n",
    "    K=classes.size\n",
    "    theta = np.ones((K,1))\n",
    "    mu_jk = np.ones((K,D))\n",
    "    sigma_jk = np.ones((K,D))\n",
    "    for k in range(0,K):\n",
    "        theta[k]= noElementOfClass[k] \n",
    "        ide = np.where(y_train==classes[k])[-1]\n",
    "        X=[]\n",
    "        for i in ide:\n",
    "             X.append(X_train[i][:])\n",
    "        X=np.array(X)\n",
    "        mu_jk[k][:]= np.sum(X,0)/X.shape[0]\n",
    "        sigma_jk[k][:]= np.square(X[k][:]-mu_jk[k][:])/X.shape[0]\n",
    "    theta/=N\n",
    "    return theta, mu_jk, sigma_jk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(theta, mu_jk, sigma_jk, x):\n",
    "    K,D = mu_jk.shape\n",
    "    p= np.ones((K,1))\n",
    "    for k in range(0, K):\n",
    "        l=np.log(1/np.sqrt(2*np.pi*sigma_jk[k][:]))-(np.square(x[:]-mu_jk[k][:])/(2*sigma_jk[k][:]))\n",
    "        p[k] = np.log(theta[k])+np.sum(l)\n",
    "    return np.argmax(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(theta, mu_jk, sigma_jk,X, y):\n",
    "    K, D = sigma_jk.shape\n",
    "    N, D  = X.shape\n",
    "    y_pre = np.ones((N,1))\n",
    "    count =0;\n",
    "    for j in range(N):\n",
    "        y_pre[j] = classify(theta, mu_jk, sigma_jk, X[j][:])\n",
    "        if y_pre[j]==y[j]:\n",
    "            count+=1\n",
    "    return count/N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of dict folder 1:  2617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: RuntimeWarning: invalid value encountered in subtract\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accurracy_test of folder 1:  0.5125 \n",
      "accurracy_train of folder 1:  0.5176848874598071\n",
      "len of dict folder 2:  2737\n",
      "accurracy_test of folder 2:  0.55 \n",
      "accurracy_train of folder 2:  0.5112540192926045\n",
      "len of dict folder 3:  2592\n",
      "accurracy_test of folder 3:  0.4 \n",
      "accurracy_train of folder 3:  0.5434083601286174\n",
      "len of dict folder 4:  2580\n",
      "accurracy_test of folder 4:  0.65 \n",
      "accurracy_train of folder 4:  0.4855305466237942\n",
      "len of dict folder 5:  2716\n",
      "accurracy_test of folder 5:  0.4647887323943662 \n",
      "accurracy_train of folder 5:  0.5264797507788161\n",
      "average accurracy_train :  0.5168715128567278\n",
      "average accurracy_test :  0.5154577464788732\n"
     ]
    }
   ],
   "source": [
    "sum_acc_test = 0\n",
    "aver_acc_test = 0\n",
    "sum_acc_train = 0\n",
    "aver_acc_train = 0\n",
    "for i in range(1, 6):\n",
    "    A = np.loadtxt('data/train{}.txt'.format(i))\n",
    "    X_train = np.array(A[:, 1: ])\n",
    "    y_train = np.array(A[:, 0])\n",
    "    print('len of dict folder {}: '.format(i), X_train.shape[1])\n",
    "    T = np.loadtxt('data/test{}.txt'.format(i))\n",
    "    X_test=np.array(T[:, 1: ])\n",
    "    y_test=np.array(T[:, 0])\n",
    "    theta, mu_jk, sigma_jk=training(X_train, y_train)\n",
    "    \n",
    "    acc_test = accuracy(theta, mu_jk, sigma_jk,X_test, y_test)\n",
    "    \n",
    "    acc_train = accuracy(theta, mu_jk, sigma_jk,X_train, y_train)\n",
    "    \n",
    "    sum_acc_test = sum_acc_test + acc_test\n",
    "    sum_acc_train = sum_acc_train + acc_train\n",
    "    \n",
    "    print('accurracy_test of folder {}: '.format(i), acc_test, '')\n",
    "    print('accurracy_train of folder {}: '.format(i), acc_train)\n",
    "    \n",
    "aver_acc_train = sum_acc_train/5\n",
    "aver_acc_test = sum_acc_test/5\n",
    "\n",
    "print('average accurracy_train : ', aver_acc_train)\n",
    "print('average accurracy_test : ', aver_acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
